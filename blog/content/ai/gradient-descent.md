Title: Gradient Descent. Perceptron.
Date: 2016-08-22
Status: Draft

# Why do we need it?
The goal of ML/DL is to make accurate predictions.
A more convenient way of looking at it, is minimizing the error.
Gradient descent gives us an optimal way to minimize the error.
Plot error and weight, it looks like this.
We need to figure out the direction and amount in which to move.
(negative)Derivative/slope points us to where the error is smaller, and tells by how much we need to change.

We move in the knob_weight value opposite the gradient value, which descends our error to 0. 


